{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Machine Learning Project\n",
    "\n",
    "This project demonstrates the application of the Logistic Regression model on a real-world dataset. In this example, we use the Breast Cancer Wisconsin (Diagnostic) dataset to classify tumors as malignant or benign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, our objective is to apply Logistic Regression to predict whether a breast tumor is malignant or benign. Logistic Regression is a fundamental classification algorithm that models the probability of a binary outcome using the sigmoid (logistic) function. Its simplicity and interpretability make it a popular choice for medical diagnosis and many other applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description & Exploratory Data Analysis (EDA)\n",
    "\n",
    "We use the Breast Cancer Wisconsin (Diagnostic) dataset available in scikit-learn. The dataset consists of 30 features computed from images of a fine needle aspirate (FNA) of a breast mass along with a target variable that indicates whether the tumor is malignant (1) or benign (0).\n",
    "\n",
    "In the following section, we load the data, display summary statistics, plot key visualizations, and uncover potential patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit-learn's breast cancer dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target  # Add target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(\"First five rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Distribution of the target variable\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "display(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix heatmap\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(df.corr(), annot=False, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of a few selected features\n",
    "features_to_plot = ['mean radius', 'mean texture', 'mean perimeter', 'mean area']\n",
    "df[features_to_plot].hist(bins=20, figsize=(10,8))\n",
    "plt.suptitle('Histograms of Selected Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In the preprocessing step, we first check for missing values and then separate our dataset into features and target. Although this dataset does not contain missing values, we proceed with feature scaling using StandardScaler. Finally, we split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in the dataset:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "features = X.columns  # Store feature names for later reference\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Explanation\n",
    "\n",
    "Logistic Regression estimates the probability that a given input x belongs to a particular class (e.g., malignant or benign) using the sigmoid function. The key equations are:\n",
    "\n",
    "**Sigmoid function:**\n",
    "\n",
    "$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $\n",
    "\n",
    "where $z = w^Tx + b$ .\n",
    "\n",
    "For binary classification, we model the probability:\n",
    "\n",
    "$P(y=1|x) = \\sigma(w^Tx + b)$\n",
    "\n",
    "The corresponding cost (log-loss) function is:\n",
    "\n",
    "$J(w, b) = -\\left[ y \\log(\\sigma(z)) + (1-y) \\log(1-\\sigma(z)) \\right]$\n",
    "\n",
    "The optimization of the parameters \\( w \\) and \\( b \\) is typically performed using gradient descent or other numerical solvers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation\n",
    "\n",
    "We now train a Logistic Regression model using scikit-learn. The dataset is split into training and testing sets, and we evaluate the model using metrics such as accuracy, precision, recall, F1-score, and ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=10000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot the ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, marker='.', label='Logistic Regression')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Random Chance')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis & Visualization\n",
    "\n",
    "In this section, we analyze the model's coefficients to understand the impact of each feature. In addition, we reduce the feature space to two dimensions using PCA to visualize the decision boundaries of the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to display model coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': features,  # Using stored feature names\n",
    "    'Coefficient': model.coef_[0]\n",
    "})\n",
    "print(\"Model Coefficients:\")\n",
    "display(coef_df.sort_values(by='Coefficient', key=abs, ascending=False))\n",
    "\n",
    "# Reduce data to 2 dimensions using PCA for visualization\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA on the training and testing data\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Retrain Logistic Regression on PCA-transformed data\n",
    "model_pca = LogisticRegression(max_iter=10000, random_state=42)\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Create a mesh grid for plotting the decision boundary\n",
    "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "\n",
    "# Predict on the mesh grid\n",
    "Z = model_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='RdBu')\n",
    "scatter = plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=y_test, s=50, cmap='RdBu', edgecolor='k')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Decision Boundary on PCA-transformed Data')\n",
    "plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "The Logistic Regression model shows reasonable performance on the Breast Cancer dataset. Its simplicity makes it highly interpretable, and the coefficients provide insight into how each feature contributes to the classification decision. However, the model may not capture complex nonlinear relationships and may be sensitive to outliers. Future work might involve exploring advanced models or additional feature engineering to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project demonstrated the process of developing a Logistic Regression model for binary classification using a real-world dataset. From data exploration and preprocessing to model training and evaluation, each step provided valuable insights. The visualizations and evaluation metrics confirm that Logistic Regression can be an effective baseline model for classification tasks, while also highlighting areas for future improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Breast Cancer Wisconsin (Diagnostic) Data Set, available via scikit-learn.\n",
    "- Scikit-learn Documentation: https://scikit-learn.org/\n",
    "- Various online resources on Logistic Regression and machine learning best practices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
